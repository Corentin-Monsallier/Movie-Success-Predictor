{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1defadf7",
   "metadata": {},
   "source": [
    "# Movie Success Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf038df",
   "metadata": {},
   "source": [
    "## 1. Installing & Importing Required Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65372f0b",
   "metadata": {},
   "source": [
    "```pip install numpy``` <br>\n",
    "```pip install pandas``` <br>\n",
    "```pip install seaborn``` <br>\n",
    "```pip install matplotlib``` <br>\n",
    "\n",
    "```pip install kagglehub``` <br>\n",
    "```pip install kagglehub[pandas-datasets]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba2f019c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57df4df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb6a119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "from kagglehub import KaggleDatasetAdapter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d4fb87",
   "metadata": {},
   "source": [
    "## 2. Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "557007c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_credits = \"tmdb_5000_credits.csv\"\n",
    "file_path_movies = \"tmdb_5000_movies.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7891a2dd",
   "metadata": {},
   "source": [
    "### 2.1. Loading the Dataset with KaggleHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17959a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credits = kagglehub.load_dataset(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"tmdb/tmdb-movie-metadata\",\n",
    "  file_path_credits,\n",
    "  # Provide any additional arguments like \n",
    "  # sql_query or pandas_kwargs. See the \n",
    "  # documenation for more information:\n",
    "  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n",
    ")\n",
    "\n",
    "df_movies = kagglehub.load_dataset(\n",
    "  KaggleDatasetAdapter.PANDAS,\n",
    "  \"tmdb/tmdb-movie-metadata\",\n",
    "  file_path_movies,\n",
    "  # Provide any additional arguments like \n",
    "  # sql_query or pandas_kwargs. See the \n",
    "  # documenation for more information:\n",
    "  # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df7d1dd",
   "metadata": {},
   "source": [
    "### 2.2. Loading the CSV Locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e3b1f0",
   "metadata": {},
   "source": [
    "If the KaggleHub import doesn't work, we can also import the dataset from a local CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26b14cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credits = pd.read_csv(f\"./data/{file_path_credits}\")\n",
    "df_movies = pd.read_csv(f\"./data/{file_path_movies}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4631bead",
   "metadata": {},
   "source": [
    "## 3. Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae345de0",
   "metadata": {},
   "source": [
    "### 3.1. Merging the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4962cd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credits.rename(columns={\"movie_id\": \"id\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bca95926",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_movies.merge(df_credits, on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9d8ff3",
   "metadata": {},
   "source": [
    "### 3.2. Remove the unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1bc415f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('homepage', axis=1)\n",
    "df = df.drop('original_title', axis=1)\n",
    "df = df.drop('overview', axis=1)\n",
    "df = df.drop('tagline', axis=1)\n",
    "df = df.drop('status', axis=1)\n",
    "df = df.drop('title_x', axis=1)\n",
    "df = df.drop('title_y', axis=1)\n",
    "df = df.drop('spoken_languages', axis=1)\n",
    "df = df.drop('production_countries', axis=1)\n",
    "df = df.drop('production_companies', axis=1)\n",
    "df = df.drop('crew', axis=1)\n",
    "df = df.drop('keywords', axis=1)\n",
    "df = df.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f91ee4d",
   "metadata": {},
   "source": [
    "> It would be great to be able to analyse the cast and its popularity, but for symplicity's sake, we'll unfortunately just drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ee33816",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('cast', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b072440d",
   "metadata": {},
   "source": [
    "### 3.3. Remove missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d9381c",
   "metadata": {},
   "source": [
    "> I would normally remplace the datas in the columns **budget** and **revenue**, but there are to many missing datas to extrapolate from the rest of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d808963",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[df['genres'] == '[]'].index)\n",
    "df = df.drop(df[df['budget'] == 0].index)\n",
    "df = df.drop(df[df['revenue'] == 0].index)\n",
    "df = df.drop(df[df['runtime'].isnull()].index)\n",
    "df = df.drop(df[df['release_date'].isnull()].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcddf8b",
   "metadata": {},
   "source": [
    "### 3.4. Convert Strings to numerical format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf09578",
   "metadata": {},
   "source": [
    "#### 3.4.1. Map movie languages to a language_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e273a584",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['original_language'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d61010e",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages_dict = {}\n",
    "language_id = 0\n",
    "for lang in df['original_language'].unique():\n",
    "    languages_dict[lang] = language_id\n",
    "    language_id += 1\n",
    "df['original_language'] = df['original_language'].map(languages_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de0e05e",
   "metadata": {},
   "source": [
    "#### 3.4.2. Decomposing the release date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37eb2de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"year\"] = [None] * len(df)\n",
    "df[\"month\"] = [None] * len(df)\n",
    "df[\"day\"] = [None] * len(df)\n",
    "date_order = [\"year\", \"month\", \"day\"]\n",
    "\n",
    "for col, row in df.iterrows():\n",
    "    date_parts = row.release_date.split(\"-\")\n",
    "    for i in range(len(date_order)):\n",
    "        df.loc[col, date_order[i]] = date_parts[i]\n",
    "\n",
    "df = df.drop(\"release_date\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8de9d87",
   "metadata": {},
   "source": [
    "#### 3.4.3 Separate each genre and actors into a colummn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9e8bf6",
   "metadata": {},
   "source": [
    "##### 3.4.3.1 Convert genres json format to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7c3c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_genres(json_str):\n",
    "    try:\n",
    "        items = json.loads(json_str.replace(\"'\", '\"'))\n",
    "        return [g[\"name\"] for g in items]\n",
    "    except:\n",
    "        return []\n",
    "    \n",
    "df[\"genres\"] = df[\"genres\"].apply(extract_genres)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6973a777",
   "metadata": {},
   "source": [
    "##### 3.4.3.2 Create a column for each genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d66c6599",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres_set = set()\n",
    "for film_genres in df[\"genres\"]:\n",
    "    for elem in film_genres:\n",
    "        genres_set.add(f\"genre_{elem.lower()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad9dbbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_order = []\n",
    "for genre in genres_set:\n",
    "    df[genre] = 0 * len(df)\n",
    "    genre_order.append(genre)\n",
    "\n",
    "for col, row in df.iterrows():\n",
    "    for i in range(len(genre_order)):\n",
    "        if genre_order[i][6:].replace('_', ' ').title() in row.genres:\n",
    "            df.loc[col, genre_order[i]] = 1\n",
    "\n",
    "df = df.drop(\"genres\", axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
